{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG13.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdgKR9Ab6NJT",
        "outputId": "692ed1cb-679d-4a4b-9f3e-21819107a877",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utoZFRdjhtZ0",
        "outputId": "05453a14-d9e0-41ac-ce5d-19257272ec0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!unzip -q \"/content/drive/My Drive/color.zip\" -d \"/content/drive/My Drive/color_new\"\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "replace /content/drive/My Drive/color_new/color/.idea/color.iml? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUU_t0ZNaIaA",
        "outputId": "529df44c-d3ab-4378-a99c-00f36515474c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import cv2\n",
        "from os import listdir\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from keras.models import Sequential\n",
        "from keras import regularizers\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.callbacks import CSVLogger, ReduceLROnPlateau, EarlyStopping\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation, Flatten, Dropout, Dense\n",
        "from keras import backend as K\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkcAixnzfyhR"
      },
      "source": [
        "batch_size = 32\n",
        "epochs = 20\n",
        "width=224\n",
        "height=224\n",
        "depth=3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ve2yHtKwnfh5"
      },
      "source": [
        "\n",
        "image_size = 0\n",
        "default_image_size = tuple((224, 224))\n",
        "directory_root = '/content/drive/My Drive/color_new/color'\n",
        "INIT_LR = 1e-3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmosGcOdqsN1"
      },
      "source": [
        "def convert_image_to_array (image_dir):\n",
        "  try:\n",
        "    image = cv2.imread (image_dir)\n",
        "    if image is not None:\n",
        "      image = cv2.resize (image, default_image_size)\n",
        "      return img_to_array(image)\n",
        "    else:\n",
        "      return np.array([])\n",
        "  except Exception as e:\n",
        "    print (\"Exception:\", e)\n",
        "    return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2e8ZSfHSqsWb",
        "outputId": "a13ea82e-e878-492f-ad94-05cafad813bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        }
      },
      "source": [
        "image_ls =[]\n",
        "label_ls = []\n",
        "\n",
        "try:\n",
        "  print (\"Loading images\")\n",
        "  root = listdir (directory_root)\n",
        "  for folder in root:\n",
        "    if folder==\".idea\":\n",
        "      root.remove(folder)\n",
        "  for plant_disease_folder in root:\n",
        "    print (f\"[INFO] Processing {plant_disease_folder} ...\")\n",
        "    plant_disease_image_list = listdir(f\"{directory_root}/{plant_disease_folder}/\")\n",
        "    #print (plant_disease_image_list)\n",
        "    image_list = listdir (f\"{directory_root}/{plant_disease_folder}/\")\n",
        "    for single_image in image_list [:600]:\n",
        "      image_dir = f\"{directory_root}/{plant_disease_folder}/{single_image}\"\n",
        "      if image_dir.endswith(\".jpg\") == True or image_dir.endswith(\".JPG\") == True:\n",
        "        image_ls.append(convert_image_to_array(image_dir))\n",
        "        label_ls.append(plant_disease_folder)\n",
        "  print(\"[INFO] Image loading completed\") \n",
        "except Exception as e:\n",
        "    print(f\"Error : {e}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading images\n",
            "[INFO] Processing Pepper,_bell___Bacterial_spot ...\n",
            "[INFO] Processing Pepper,_bell___healthy ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-1deebc18dfbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0mimage_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{directory_root}/{plant_disease_folder}/{single_image}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mimage_dir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".jpg\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mimage_dir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".JPG\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mimage_ls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert_image_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mlabel_ls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplant_disease_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[INFO] Image loading completed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-7733842af767>\u001b[0m in \u001b[0;36mconvert_image_to_array\u001b[0;34m(image_dir)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconvert_image_to_array\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_image_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_jxXgFgqsZO"
      },
      "source": [
        "img_size = len (image_ls)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tifWBKXOQTh5",
        "outputId": "57ad11e8-0079-483b-f984-a71b586ed06d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "img_list = []\n",
        "label_list=[]\n",
        "try:\n",
        "  print (\"Loading image\")\n",
        "  root = listdir (directory_root)\n",
        "  for folder in root:\n",
        "    if folder==\".idea\":\n",
        "      root.remove(folder)\n",
        "  for plant_disease_folder in root[10:11]:\n",
        "    print (f\"[INFO] Processing {plant_disease_folder} ...\")\n",
        "    plant_disease_image_list = listdir(f\"{directory_root}/{plant_disease_folder}/\")\n",
        "    #print (plant_disease_image_list)\n",
        "    image_list = listdir (f\"{directory_root}/{plant_disease_folder}/\")\n",
        "    for single_image in image_list [1:2]:\n",
        "      image_dir = f\"{directory_root}/{plant_disease_folder}/{single_image}\"\n",
        "      if image_dir.endswith(\".jpg\") == True or image_dir.endswith(\".JPG\") == True:\n",
        "        img_list.append(convert_image_to_array(image_dir))\n",
        "        label_list.append(plant_disease_folder)\n",
        "  print(\"[INFO] Image loading completed\") \n",
        "except Exception as e:\n",
        "    print(f\"Error : {e}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading image\n",
            "[INFO] Processing Tomato___Septoria_leaf_spot ...\n",
            "[INFO] Image loading completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUAOWKMFqsee",
        "outputId": "fe2510a5-5e94-45eb-c6a2-408021d3d7e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "#Transform image labels \n",
        "\n",
        "labelbinarizer = LabelBinarizer()\n",
        "img_labels = labelbinarizer.fit_transform (label_ls)\n",
        "pickle.dump (labelbinarizer, open('LabelTransform.pkl', 'wb'))\n",
        "no_of_classes = len(labelbinarizer.classes_)\n",
        "print (no_of_classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-7781b75e659d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlabelbinarizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelBinarizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mimg_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabelbinarizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_ls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabelbinarizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LabelTransform.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mno_of_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabelbinarizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'label_ls' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIv4FWG3qsjy",
        "outputId": "70e91161-b0e5-4bd2-8d84-e03ee76d2b85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "print (labelbinarizer.classes_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Pepper,_bell___Bacterial_spot' 'Pepper,_bell___healthy'\n",
            " 'Potato___Early_blight' 'Potato___Late_blight' 'Potato___healthy'\n",
            " 'Tomato___Bacterial_spot' 'Tomato___Early_blight' 'Tomato___Late_blight'\n",
            " 'Tomato___Leaf_Mold' 'Tomato___Septoria_leaf_spot'\n",
            " 'Tomato___Spider_mites Two-spotted_spider_mite' 'Tomato___Target_Spot'\n",
            " 'Tomato___Tomato_Yellow_Leaf_Curl_Virus' 'Tomato___Tomato_mosaic_virus'\n",
            " 'Tomato___healthy']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWdN5PO0qsow"
      },
      "source": [
        "np_img_list = np.array (image_ls, dtype = np.float16) / 225.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjN0YUl2RRqR"
      },
      "source": [
        "np_img_ls = np.array(img_list,dtype=np.float16) / 225.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIqYAuUTqsiu"
      },
      "source": [
        "#Splitting data into training and validation\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split (np_img_list, img_labels, test_size = 0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aiFXIM3qsdN"
      },
      "source": [
        "aug = ImageDataGenerator (rotation_range = 25, width_shift_range = 0.1, height_shift_range = 0.1, shear_range=0.2, zoom_range=0.2, horizontal_flip=True, fill_mode=\"nearest\" )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAH1Ohygsu34"
      },
      "source": [
        "no_of_classes = 15\n",
        "\n",
        "model = Sequential()\n",
        "input_shape = (height,width, depth)\n",
        "chanDim = -1\n",
        "if K.image_data_format() == \"channels_first\":\n",
        "    input_shape = (depth, height, width)\n",
        "    chanDim = 1\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\",input_shape=input_shape))\n",
        "model.add(Activation(\"relu\"))\n",
        "#model.add(BatchNormalization(axis=chanDim))\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "#model.add(BatchNormalization(axis=chanDim))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Conv2D(128, (3, 3), padding=\"valid\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "#model.add(BatchNormalization(axis=chanDim))\n",
        "model.add(Conv2D(128, (3, 3), padding=\"valid\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "#model.add(BatchNormalization(axis=chanDim))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='valid'))\n",
        "#model.add(BatchNormalization(axis=chanDim))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='valid'))\n",
        "#model.add(BatchNormalization(axis=chanDim))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', padding='valid'))\n",
        "#model.add(BatchNormalization(axis=chanDim))\n",
        "model.add(Dropout(0.6))\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', padding='valid'))\n",
        "#.add(BatchNormalization(axis=chanDim))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', padding='valid'))\n",
        "#model.add(BatchNormalization(axis=chanDim))\n",
        "model.add(Dropout(0.6))\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', padding='valid'))\n",
        "#model.add(BatchNormalization(axis=chanDim))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(4096, activation='relu'))\n",
        "#model.add(BatchNormalization(axis=chanDim))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(4096, activation='relu'))\n",
        "#model.add(BatchNormalization(axis=chanDim))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1000, activation='relu'))\n",
        "#model.add(BatchNormalization(axis=chanDim))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(no_of_classes))\n",
        "model.add(Activation(\"softmax\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVSIX0x4svAR",
        "outputId": "f53f6621-5420-492b-e005-dcea78a4ddc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 256, 256, 64)      1792      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 256, 256, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 256, 256, 64)      36928     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 256, 256, 64)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 128, 128, 64)      0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128, 128, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 126, 126, 128)     73856     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 126, 126, 128)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 124, 124, 128)     147584    \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 124, 124, 128)     0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 62, 62, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 62, 62, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 60, 60, 256)       295168    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 60, 60, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 58, 58, 256)       590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 29, 29, 256)       0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 29, 29, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 27, 27, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 27, 27, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 25, 25, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 12, 12, 512)       0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 12, 12, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 10, 10, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 10, 10, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4096)              33558528  \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1000)              4097000   \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 15)                15015     \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 15)                0         \n",
            "=================================================================\n",
            "Total params: 63,856,847\n",
            "Trainable params: 63,856,847\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFVbVibBuCbj"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJ-Z9qwuh5Bh"
      },
      "source": [
        "model.load_weights ('/content/drive/My Drive/MyCNN/epochs:001-val_accuracy:0.079.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrShguIHsvEF",
        "outputId": "e62e390b-9eb7-4362-919a-b42420cffb87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "optimizer = Adam (lr=INIT_LR, decay = INIT_LR/epochs)\n",
        "BS = 128\n",
        "model.compile (loss=\"categorical_crossentropy\", optimizer = optimizer, metrics = ['accuracy'])\n",
        "print (\"Train...\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDiVVr9AZl62"
      },
      "source": [
        "from keras.callbacks import *\n",
        "\n",
        "filepath = \"/content/drive/My Drive/MyCNN/epochs:{epoch:03d}-val_accuracy:{val_accuracy:.3f}.hdf5\"\n",
        "\n",
        "checkpoint = ModelCheckpoint (filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PR2szc8gsvJE",
        "outputId": "a36c0244-dcc4-4edf-b082-4331c2af9916",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "history = model.fit_generator(\n",
        "    aug.flow(x_train, y_train, batch_size=batch_size),\n",
        "    validation_data=(x_val, y_val),\n",
        "    initial_epoch=7,\n",
        "    steps_per_epoch=len(x_train) // batch_size,\n",
        "    epochs=epochs, verbose=1,\n",
        "    callbacks = callbacks_list\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 8/20\n",
            "208/208 [==============================] - 5285s 25s/step - loss: 2.6830 - accuracy: 0.0665 - val_loss: 2.6773 - val_accuracy: 0.0781\n",
            "\n",
            "Epoch 00008: val_accuracy improved from -inf to 0.07808, saving model to /content/drive/My Drive/MyCNN/epochs:008-val_accuracy:0.078.hdf5\n",
            "Epoch 9/20\n",
            "208/208 [==============================] - 5317s 26s/step - loss: 2.6801 - accuracy: 0.0708 - val_loss: 2.6775 - val_accuracy: 0.0787\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.07808 to 0.07868, saving model to /content/drive/My Drive/MyCNN/epochs:009-val_accuracy:0.079.hdf5\n",
            "Epoch 10/20\n",
            "208/208 [==============================] - 5335s 26s/step - loss: 2.6800 - accuracy: 0.0708 - val_loss: 2.6778 - val_accuracy: 0.0631\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.07868\n",
            "Epoch 11/20\n",
            "208/208 [==============================] - 5342s 26s/step - loss: 2.6812 - accuracy: 0.0690 - val_loss: 2.6774 - val_accuracy: 0.0673\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.07868\n",
            "Epoch 12/20\n",
            "208/208 [==============================] - 5338s 26s/step - loss: 2.6796 - accuracy: 0.0721 - val_loss: 2.6774 - val_accuracy: 0.0673\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.07868\n",
            "Epoch 13/20\n",
            "208/208 [==============================] - 5363s 26s/step - loss: 2.6774 - accuracy: 0.0709 - val_loss: 2.6764 - val_accuracy: 0.0787\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.07868\n",
            "Epoch 14/20\n",
            "208/208 [==============================] - 5374s 26s/step - loss: 2.6799 - accuracy: 0.0741 - val_loss: 2.6775 - val_accuracy: 0.0625\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.07868\n",
            "Epoch 15/20\n",
            "119/208 [================>.............] - ETA: 36:03 - loss: 2.6754 - accuracy: 0.0752"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_tuXsLEsu-w"
      },
      "source": [
        "plot_training(history)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Sosohljsu9N"
      },
      "source": [
        "print(\"[INFO] Calculating model accuracy\")\n",
        "scores = model.evaluate(x_val, y_val)\n",
        "print(f\"Test Accuracy: {scores[1]*100}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2TGWY8Gsu7Y"
      },
      "source": [
        "# save the model to disk\n",
        "print(\"[INFO] Saving model...\")\n",
        "pickle.dump(model,open('vgg_model_15_20_epoch.pkl', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8U_V5WXEsu1Y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7Yuza6etyW9"
      },
      "source": [
        "accu = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(accu) + 1)\n",
        "#Train and validation accuracy\n",
        "plt.plot(epochs, accu, 'b', label='Training accurary')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation accurary')\n",
        "plt.title('Training and Validation accurary')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "#Train and validation loss\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbkpl8L3RxAe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYwapyMga8Bz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxWkD94Ya8FO",
        "outputId": "5436ee61-ea70-4bb9-f2e4-24d617e0f205",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "model.predict(np_img_ls)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.068073  , 0.06854592, 0.0775432 , 0.072152  , 0.02383664,\n",
              "        0.06484511, 0.07042155, 0.06890409, 0.07088616, 0.07664508,\n",
              "        0.07566702, 0.07593176, 0.07378264, 0.04219518, 0.07057067]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psyOotiRRxDS",
        "outputId": "4cfc1b67-d2fe-44f2-e9aa-eecd59676f03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "loaded_model = tf.keras.models.load_model('/content/drive/My Drive/MyCNN/epochs:001-val_accuracy:0.079.hdf5')\n",
        "print (loaded_model.layers[0].input_shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 256, 256, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brdaEC4ESUFm",
        "outputId": "8190cc0e-82d6-48e2-aa3b-14d11bee80c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "result = loaded_model.predict_classes(np_img_ls)\n",
        "print (result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dWvUDTGSqP1",
        "outputId": "7b0f3a1b-f830-454f-e11c-f80efc19027a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print (result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpavCuhJSw0V",
        "outputId": "1e2c9927-0300-4d6c-8c77-00c3a1c77464",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "print (get_label_name(result[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-afc0ee75f339>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mget_label_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'get_label_name' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkjILYU6S4FW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdLEir2gvD5Q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j07vjssgvD9D"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oh1L37-_vEC7"
      },
      "source": [
        "directory_root = '/content/drive/My Drive/PlantVillage/output'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuRloa4MvEBW"
      },
      "source": [
        "\n",
        "import time\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch import nn\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets\n",
        "\n",
        "from itertools import accumulate\n",
        "from functools import reduce\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnJxkVfovD26"
      },
      "source": [
        "model_urls = {\n",
        "    'vgg13': 'https://download.pytorch.org/models/vgg13-c768596a.pth'   \n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUpjLrbNvpm6"
      },
      "source": [
        "model_names = model_urls.keys()\n",
        "\n",
        "input_sizes = {\n",
        "    'vgg' : (224,224)\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K48Ph9yxvt6K"
      },
      "source": [
        "models_to_test = [ 'vgg13']\n",
        "\n",
        "batch_size = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fG4ipZCnvybX"
      },
      "source": [
        "def diff_states(dict_canonical, dict_subset):\n",
        "    names1, names2 = (list(dict_canonical.keys()), list(dict_subset.keys()))\n",
        "    \n",
        "    #Sanity check that param names overlap\n",
        "    #Note that params are not necessarily in the same order\n",
        "    #for every pretrained model\n",
        "    not_in_1 = [n for n in names1 if n not in names2]\n",
        "    not_in_2 = [n for n in names2 if n not in names1]\n",
        "    assert len(not_in_1) == 0\n",
        "    assert len(not_in_2) == 0\n",
        "\n",
        "    for name, v1 in dict_canonical.items():\n",
        "        v2 = dict_subset[name]\n",
        "        assert hasattr(v2, 'size')\n",
        "        if v1.size() != v2.size():\n",
        "            yield (name, v1)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWAq4f4zv3I9"
      },
      "source": [
        "def load_defined_model(name, num_classes):\n",
        "    \n",
        "    model = models.__dict__[name](num_classes=num_classes)\n",
        "    pretrained_state = model_zoo.load_url(model_urls[name])\n",
        "    diff = [s for s in diff_states(model.state_dict(), pretrained_state)]\n",
        "    print(\"Replacing the following state from initialized\", name, \":\",[d[0] for d in diff])\n",
        "    \n",
        "    for name, value in diff:\n",
        "        pretrained_state[name] = value\n",
        "    \n",
        "    assert len([s for s in diff_states(model.state_dict(), pretrained_state)]) == 0\n",
        "    \n",
        "    model.load_state_dict(pretrained_state)\n",
        "    return model, diff\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SSZC6dJwCnb"
      },
      "source": [
        "def filtered_params(net, param_list=None):\n",
        "    def in_param_list(s):\n",
        "        for p in param_list:\n",
        "            if s.endswith(p):\n",
        "                return True\n",
        "        return False    \n",
        "    #Caution: DataParallel prefixes '.module' to every parameter name\n",
        "    params = net.named_parameters() if param_list is None else (p for p in net.named_parameters() if in_param_list(p[0]))\n",
        "    return params"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OJm9i8ZwHd9"
      },
      "source": [
        "def load_data(resize):\n",
        "\n",
        "    data_transforms = {\n",
        "        'train': transforms.Compose([\n",
        "            transforms.RandomSizedCrop(max(resize)),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "        'val': transforms.Compose([\n",
        "            #Higher scale-up for inception\n",
        "            transforms.Scale(int(max(resize)/224*256)),\n",
        "            transforms.CenterCrop(max(resize)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "    }\n",
        "\n",
        "    data_dir = '/content/drive/My Drive/PlantVillage/output'\n",
        "    dsets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n",
        "             for x in ['train', 'val']}\n",
        "    dset_loaders = {x: torch.utils.data.DataLoader(dsets[x], batch_size=batch_size,\n",
        "                                                   shuffle=True)\n",
        "                    for x in ['train', 'val']}\n",
        "    dset_sizes = {x: len(dsets[x]) for x in ['train', 'val']}\n",
        "    dset_classes = dsets['train'].classes\n",
        "    \n",
        "    return dset_loaders['train'], dset_loaders['val']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzRvCcvqwS04"
      },
      "source": [
        "def train(net, trainloader, param_list=None, epochs=15):\n",
        "    def in_param_list(s):\n",
        "        for p in param_list:\n",
        "            if s.endswith(p):\n",
        "                return True\n",
        "        return False\n",
        "    \n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    \n",
        "    \n",
        "    params = (p for p in filtered_params(net, param_list))\n",
        "    \n",
        "    #if finetuning model, turn off grad for other params\n",
        "    if param_list:\n",
        "        for p_fixed in (p for p in net.named_parameters() if not in_param_list(p[0])):\n",
        "            p_fixed[1].requires_grad = False            \n",
        "    \n",
        "    #Optimizer as in paper\n",
        "    optimizer = optim.SGD((p[1] for p in params), lr=0.001, momentum=0.9)\n",
        "\n",
        "    losses = []\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            # get the inputs\n",
        "            inputs, labels = data\n",
        "            inputs, labels = Variable(inputs), Variable(labels)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = net(inputs)\n",
        "            \n",
        "            loss = None\n",
        "            # for nets that have multiple outputs such as inception\n",
        "            if isinstance(outputs, tuple):\n",
        "                loss = sum((criterion(o,labels) for o in outputs))\n",
        "            else:\n",
        "                loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            running_loss += loss.data\n",
        "            if i % 30 == 29:\n",
        "                avg_loss = running_loss / 30\n",
        "                losses.append(avg_loss)\n",
        "                print('[%d, %5d] loss: %.3f' %\n",
        "                      (epoch + 1, i + 1, avg_loss))\n",
        "                running_loss = 0.0\n",
        "\n",
        "    print('Finished Training')\n",
        "    return losses\n",
        "\n",
        "#Get stats for training and evaluation in a structured way\n",
        "#If param_list is None all relevant parameters are tuned,\n",
        "#otherwise, only parameters that have been constructed for custom\n",
        "#num_classes\n",
        "def train_stats(m, trainloader, param_list = None):\n",
        "    stats = {}\n",
        "    params = filtered_params(m, param_list)    \n",
        "    counts = 0,0\n",
        "    for counts in enumerate(accumulate((reduce(lambda d1,d2: d1*d2, p[1].size()) for p in params)) ):\n",
        "        pass\n",
        "    stats['variables_optimized'] = counts[0] + 1\n",
        "    stats['params_optimized'] = counts[1]\n",
        "    \n",
        "    before = time.time()\n",
        "    losses = train(m, trainloader, param_list=param_list)\n",
        "    stats['training_time'] = time.time() - before\n",
        "\n",
        "    stats['training_loss'] = losses[-1] if len(losses) else float('nan')\n",
        "    stats['training_losses'] = losses\n",
        "    \n",
        "    return stats\n",
        "\n",
        "def evaluate_stats(net, testloader):\n",
        "    stats = {}\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    before = time.time()\n",
        "    for i, data in enumerate(testloader, 0):\n",
        "        images, labels = data\n",
        "\n",
        "        images, labels = (images.cuda()), (labels.cuda(async=True))\n",
        "\n",
        "        outputs = net(Variable(images))\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum()\n",
        "    accuracy = correct / total\n",
        "    stats['accuracy'] = accuracy\n",
        "    stats['eval_time'] = time.time() - before\n",
        "    \n",
        "    print('Accuracy on test images: %f' % accuracy)\n",
        "    return stats\n",
        "\n",
        "\n",
        "def train_eval(net, trainloader, testloader, param_list=None):\n",
        "    print(\"Training...\" if not param_list else \"Retraining...\")\n",
        "    stats_train = train_stats(net, trainloader, param_list=param_list)\n",
        "    \n",
        "    print(\"Evaluating...\")\n",
        "    net = net.eval()\n",
        "    stats_eval = evaluate_stats(net, testloader)\n",
        "    \n",
        "    return {**stats_train, **stats_eval}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADuXHp_3wbGn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "46c84913-8d0d-4f1b-899f-28d2f2717e93"
      },
      "source": [
        "stats = []\n",
        "num_classes = 15\n",
        "print(\"RETRAINING\")\n",
        "\n",
        "for name in models_to_test:\n",
        "    print(\"\")\n",
        "    print(\"Targeting %s with %d classes\" % (name, num_classes))\n",
        "    print(\"------------------------------------------\")\n",
        "    model_pretrained, diff = load_defined_model(name, num_classes)\n",
        "    final_params = [d[0] for d in diff]\n",
        "    #final_params = None\n",
        "    \n",
        "    resize = [s[1] for s in input_sizes.items() if s[0] in name][0]\n",
        "    print(\"Resizing input images to max of\", resize)\n",
        "    trainloader, testloader = load_data(resize)\n",
        "    \n",
        "        \n",
        "    pretrained_stats = train_eval(model_pretrained, trainloader, testloader, final_params)\n",
        "    pretrained_stats['name'] = name\n",
        "    pretrained_stats['retrained'] = True\n",
        "    pretrained_stats['shallow_retrain'] = True\n",
        "    stats.append(pretrained_stats)\n",
        "    \n",
        "    print(\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RETRAINING\n",
            "\n",
            "Targeting vgg13 with 15 classes\n",
            "------------------------------------------\n",
            "Replacing the following state from initialized vgg13 : ['classifier.6.weight', 'classifier.6.bias']\n",
            "Resizing input images to max of (224, 224)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py:698: UserWarning: The use of the transforms.RandomSizedCrop transform is deprecated, please use transforms.RandomResizedCrop instead.\n",
            "  \"please use transforms.RandomResizedCrop instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py:211: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
            "  \"please use transforms.Resize instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Retraining...\n",
            "[1,    30] loss: 2.400\n",
            "[1,    60] loss: 1.769\n",
            "[1,    90] loss: 1.373\n",
            "[1,   120] loss: 1.339\n",
            "[1,   150] loss: 1.329\n",
            "[1,   180] loss: 1.180\n",
            "[1,   210] loss: 1.222\n",
            "[1,   240] loss: 1.190\n",
            "[1,   270] loss: 1.106\n",
            "[1,   300] loss: 1.075\n",
            "[1,   330] loss: 1.015\n",
            "[1,   360] loss: 0.979\n",
            "[1,   390] loss: 0.968\n",
            "[1,   420] loss: 1.047\n",
            "[1,   450] loss: 0.949\n",
            "[1,   480] loss: 0.990\n",
            "[1,   510] loss: 0.941\n",
            "[1,   540] loss: 1.020\n",
            "[1,   570] loss: 0.994\n",
            "[1,   600] loss: 1.037\n",
            "[1,   630] loss: 0.929\n",
            "[1,   660] loss: 0.931\n",
            "[1,   690] loss: 0.907\n",
            "[1,   720] loss: 0.940\n",
            "[1,   750] loss: 1.027\n",
            "[1,   780] loss: 0.795\n",
            "[1,   810] loss: 0.997\n",
            "[1,   840] loss: 0.899\n",
            "[1,   870] loss: 0.887\n",
            "[1,   900] loss: 0.824\n",
            "[2,    30] loss: 0.820\n",
            "[2,    60] loss: 0.854\n",
            "[2,    90] loss: 0.786\n",
            "[2,   120] loss: 0.913\n",
            "[2,   150] loss: 0.870\n",
            "[2,   180] loss: 0.794\n",
            "[2,   210] loss: 0.804\n",
            "[2,   240] loss: 0.883\n",
            "[2,   270] loss: 0.949\n",
            "[2,   300] loss: 0.845\n",
            "[2,   330] loss: 0.769\n",
            "[2,   360] loss: 0.872\n",
            "[2,   390] loss: 0.824\n",
            "[2,   420] loss: 0.824\n",
            "[2,   450] loss: 0.867\n",
            "[2,   480] loss: 0.783\n",
            "[2,   510] loss: 0.834\n",
            "[2,   540] loss: 0.870\n",
            "[2,   570] loss: 0.805\n",
            "[2,   600] loss: 0.828\n",
            "[2,   630] loss: 0.835\n",
            "[2,   660] loss: 0.821\n",
            "[2,   690] loss: 0.860\n",
            "[2,   720] loss: 0.781\n",
            "[2,   750] loss: 0.857\n",
            "[2,   780] loss: 0.870\n",
            "[2,   810] loss: 0.831\n",
            "[2,   840] loss: 0.858\n",
            "[2,   870] loss: 0.804\n",
            "[2,   900] loss: 0.843\n",
            "[3,    30] loss: 0.809\n",
            "[3,    60] loss: 0.793\n",
            "[3,    90] loss: 0.824\n",
            "[3,   120] loss: 0.778\n",
            "[3,   150] loss: 0.669\n",
            "[3,   180] loss: 0.814\n",
            "[3,   210] loss: 0.752\n",
            "[3,   240] loss: 0.801\n",
            "[3,   270] loss: 0.715\n",
            "[3,   300] loss: 0.829\n",
            "[3,   330] loss: 0.756\n",
            "[3,   360] loss: 0.773\n",
            "[3,   390] loss: 0.868\n",
            "[3,   420] loss: 0.794\n",
            "[3,   450] loss: 0.695\n",
            "[3,   480] loss: 0.872\n",
            "[3,   510] loss: 0.746\n",
            "[3,   540] loss: 0.827\n",
            "[3,   570] loss: 0.758\n",
            "[3,   600] loss: 0.889\n",
            "[3,   630] loss: 0.708\n",
            "[3,   660] loss: 0.873\n",
            "[3,   690] loss: 0.748\n",
            "[3,   720] loss: 0.745\n",
            "[3,   750] loss: 0.770\n",
            "[3,   780] loss: 0.744\n",
            "[3,   810] loss: 0.792\n",
            "[3,   840] loss: 0.860\n",
            "[3,   870] loss: 0.798\n",
            "[3,   900] loss: 0.772\n",
            "[4,    30] loss: 0.716\n",
            "[4,    60] loss: 0.776\n",
            "[4,    90] loss: 0.769\n",
            "[4,   120] loss: 0.734\n",
            "[4,   150] loss: 0.840\n",
            "[4,   180] loss: 0.819\n",
            "[4,   210] loss: 0.735\n",
            "[4,   240] loss: 0.851\n",
            "[4,   270] loss: 0.755\n",
            "[4,   300] loss: 0.838\n",
            "[4,   330] loss: 0.701\n",
            "[4,   360] loss: 0.700\n",
            "[4,   390] loss: 0.753\n",
            "[4,   420] loss: 0.899\n",
            "[4,   450] loss: 0.765\n",
            "[4,   480] loss: 0.755\n",
            "[4,   510] loss: 0.700\n",
            "[4,   540] loss: 0.781\n",
            "[4,   570] loss: 0.756\n",
            "[4,   600] loss: 0.746\n",
            "[4,   630] loss: 0.721\n",
            "[4,   660] loss: 0.773\n",
            "[4,   690] loss: 0.708\n",
            "[4,   720] loss: 0.666\n",
            "[4,   750] loss: 0.813\n",
            "[4,   780] loss: 0.751\n",
            "[4,   810] loss: 0.819\n",
            "[4,   840] loss: 0.758\n",
            "[4,   870] loss: 0.724\n",
            "[4,   900] loss: 0.730\n",
            "[5,    30] loss: 0.821\n",
            "[5,    60] loss: 0.846\n",
            "[5,    90] loss: 0.748\n",
            "[5,   120] loss: 0.694\n",
            "[5,   150] loss: 0.676\n",
            "[5,   180] loss: 0.689\n",
            "[5,   210] loss: 0.726\n",
            "[5,   240] loss: 0.700\n",
            "[5,   270] loss: 0.742\n",
            "[5,   300] loss: 0.748\n",
            "[5,   330] loss: 0.763\n",
            "[5,   360] loss: 0.688\n",
            "[5,   390] loss: 0.664\n",
            "[5,   420] loss: 0.715\n",
            "[5,   450] loss: 0.732\n",
            "[5,   480] loss: 0.778\n",
            "[5,   510] loss: 0.784\n",
            "[5,   540] loss: 0.730\n",
            "[5,   570] loss: 0.710\n",
            "[5,   600] loss: 0.798\n",
            "[5,   630] loss: 0.743\n",
            "[5,   660] loss: 0.705\n",
            "[5,   690] loss: 0.719\n",
            "[5,   720] loss: 0.819\n",
            "[5,   750] loss: 0.774\n",
            "[5,   780] loss: 0.702\n",
            "[5,   810] loss: 0.817\n",
            "[5,   840] loss: 0.749\n",
            "[5,   870] loss: 0.746\n",
            "[5,   900] loss: 0.753\n",
            "[6,    30] loss: 0.747\n",
            "[6,    60] loss: 0.763\n",
            "[6,    90] loss: 0.650\n",
            "[6,   120] loss: 0.738\n",
            "[6,   150] loss: 0.713\n",
            "[6,   180] loss: 0.804\n",
            "[6,   210] loss: 0.735\n",
            "[6,   240] loss: 0.687\n",
            "[6,   270] loss: 0.763\n",
            "[6,   300] loss: 0.796\n",
            "[6,   330] loss: 0.750\n",
            "[6,   360] loss: 0.767\n",
            "[6,   390] loss: 0.739\n",
            "[6,   420] loss: 0.687\n",
            "[6,   450] loss: 0.795\n",
            "[6,   480] loss: 0.765\n",
            "[6,   510] loss: 0.735\n",
            "[6,   540] loss: 0.765\n",
            "[6,   570] loss: 0.692\n",
            "[6,   600] loss: 0.728\n",
            "[6,   630] loss: 0.748\n",
            "[6,   660] loss: 0.623\n",
            "[6,   690] loss: 0.712\n",
            "[6,   720] loss: 0.712\n",
            "[6,   750] loss: 0.700\n",
            "[6,   780] loss: 0.812\n",
            "[6,   810] loss: 0.820\n",
            "[6,   840] loss: 0.785\n",
            "[6,   870] loss: 0.738\n",
            "[6,   900] loss: 0.727\n",
            "[7,    30] loss: 0.681\n",
            "[7,    60] loss: 0.735\n",
            "[7,    90] loss: 0.796\n",
            "[7,   120] loss: 0.756\n",
            "[7,   150] loss: 0.671\n",
            "[7,   180] loss: 0.662\n",
            "[7,   210] loss: 0.836\n",
            "[7,   240] loss: 0.678\n",
            "[7,   270] loss: 0.738\n",
            "[7,   300] loss: 0.775\n",
            "[7,   330] loss: 0.723\n",
            "[7,   360] loss: 0.748\n",
            "[7,   390] loss: 0.782\n",
            "[7,   420] loss: 0.718\n",
            "[7,   450] loss: 0.640\n",
            "[7,   480] loss: 0.757\n",
            "[7,   510] loss: 0.715\n",
            "[7,   540] loss: 0.821\n",
            "[7,   570] loss: 0.767\n",
            "[7,   600] loss: 0.776\n",
            "[7,   630] loss: 0.632\n",
            "[7,   660] loss: 0.798\n",
            "[7,   690] loss: 0.694\n",
            "[7,   720] loss: 0.705\n",
            "[7,   750] loss: 0.748\n",
            "[7,   780] loss: 0.726\n",
            "[7,   810] loss: 0.777\n",
            "[7,   840] loss: 0.741\n",
            "[7,   870] loss: 0.757\n",
            "[7,   900] loss: 0.697\n",
            "[8,    30] loss: 0.767\n",
            "[8,    60] loss: 0.656\n",
            "[8,    90] loss: 0.758\n",
            "[8,   120] loss: 0.683\n",
            "[8,   150] loss: 0.733\n",
            "[8,   180] loss: 0.720\n",
            "[8,   210] loss: 0.747\n",
            "[8,   240] loss: 0.721\n",
            "[8,   270] loss: 0.742\n",
            "[8,   300] loss: 0.688\n",
            "[8,   330] loss: 0.849\n",
            "[8,   360] loss: 0.699\n",
            "[8,   390] loss: 0.793\n",
            "[8,   420] loss: 0.723\n",
            "[8,   450] loss: 0.704\n",
            "[8,   480] loss: 0.671\n",
            "[8,   510] loss: 0.778\n",
            "[8,   540] loss: 0.653\n",
            "[8,   570] loss: 0.621\n",
            "[8,   600] loss: 0.808\n",
            "[8,   630] loss: 0.699\n",
            "[8,   660] loss: 0.691\n",
            "[8,   690] loss: 0.688\n",
            "[8,   720] loss: 0.728\n",
            "[8,   750] loss: 0.731\n",
            "[8,   780] loss: 0.720\n",
            "[8,   810] loss: 0.765\n",
            "[8,   840] loss: 0.748\n",
            "[8,   870] loss: 0.727\n",
            "[8,   900] loss: 0.662\n",
            "[9,    30] loss: 0.786\n",
            "[9,    60] loss: 0.796\n",
            "[9,    90] loss: 0.742\n",
            "[9,   120] loss: 0.698\n",
            "[9,   150] loss: 0.701\n",
            "[9,   180] loss: 0.728\n",
            "[9,   210] loss: 0.742\n",
            "[9,   240] loss: 0.657\n",
            "[9,   270] loss: 0.685\n",
            "[9,   300] loss: 0.692\n",
            "[9,   330] loss: 0.731\n",
            "[9,   360] loss: 0.720\n",
            "[9,   390] loss: 0.687\n",
            "[9,   420] loss: 0.723\n",
            "[9,   450] loss: 0.733\n",
            "[9,   480] loss: 0.761\n",
            "[9,   510] loss: 0.712\n",
            "[9,   540] loss: 0.784\n",
            "[9,   570] loss: 0.678\n",
            "[9,   600] loss: 0.782\n",
            "[9,   630] loss: 0.688\n",
            "[9,   660] loss: 0.811\n",
            "[9,   690] loss: 0.655\n",
            "[9,   720] loss: 0.646\n",
            "[9,   750] loss: 0.692\n",
            "[9,   780] loss: 0.823\n",
            "[9,   810] loss: 0.704\n",
            "[9,   840] loss: 0.752\n",
            "[9,   870] loss: 0.721\n",
            "[9,   900] loss: 0.673\n",
            "[10,    30] loss: 0.725\n",
            "[10,    60] loss: 0.773\n",
            "[10,    90] loss: 0.678\n",
            "[10,   120] loss: 0.690\n",
            "[10,   150] loss: 0.719\n",
            "[10,   180] loss: 0.657\n",
            "[10,   210] loss: 0.682\n",
            "[10,   240] loss: 0.716\n",
            "[10,   270] loss: 0.738\n",
            "[10,   300] loss: 0.734\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJDiB4Xpw0OD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}